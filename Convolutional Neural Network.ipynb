{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n* 32 feature detector-->32 feature maps (size of 5x5). (64 if using a GPU)\\n* feature detector consists of 3 rows and 3 columns.\\n\\n* input_shape= shape of input image (converting all images to fixed size/image format)\\n* since the images are color images, they will be converted into 3-D arrays.\\n* 64x64 format (128 or 256 if using a GPU)\\n\\n* activation function 'relu' is most commonly used for CNN.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(64, (3, 3), input_shape=(128, 128, 3), activation='relu'))\n",
    "\n",
    "'''\n",
    "* 32 feature detector-->32 feature maps (size of 5x5). (64 if using a GPU)\n",
    "* feature detector consists of 3 rows and 3 columns.\n",
    "\n",
    "* input_shape= shape of input image (converting all images to fixed size/image format)\n",
    "* since the images are color images, they will be converted into 3-D arrays.\n",
    "* 64x64 format (128 or 256 if using a GPU)\n",
    "\n",
    "* activation function 'relu' is most commonly used for CNN.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Max Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "'''reduces the size of our feature maps into 2x2 (reducing the complexity of the model).'''\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n* activation function 'sigmoid' because we have a binary outcome. If we have more, need to use 'softmax'.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "'''\n",
    "* units= number of nodes in the hidden layer(full connection).\n",
    "\n",
    "* 128 is not too small, but it can be higher if using GPU.\n",
    "\n",
    "* activation function 'relu' is most commonly used for CNN.\n",
    "'''\n",
    "\n",
    "# Final output layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "'''\n",
    "* activation function 'sigmoid' because we have a binary outcome. If we have more, need to use 'softmax'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n* 'adam' is a good stochastic gradient descent optimizer for CNN.\\n\\n* cross entropy loss function is usually used for classifcation problems. Because we have a binary outcome, we\\nuse 'binary_crossentropy'. If we had more we'd need to use 'categorical_crossentropy'.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "''' \n",
    "* 'adam' is a good stochastic gradient descent optimizer for CNN.\n",
    "\n",
    "* cross entropy loss function is usually used for classifcation problems. Because we have a binary outcome, we\n",
    "use 'binary_crossentropy'. If we had more we'd need to use 'categorical_crossentropy'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## Part 2 - Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "'''\n",
    "* Image Data Generator is the first step the Image Augmentation which will help prevent overfitting\n",
    "(when we have few data points to train our model).\n",
    "\n",
    "* It creates many batches of the images, and for each batch it will apply some random transformations to them so\n",
    "we'll get many more diverse images within these batches.'''\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "'''\n",
    "* rescale the images to a standard size\n",
    "* shear_range is a geomatrical transformation of the pixels.\n",
    "* zoom_range is a random zoom we apply to the images.\n",
    "'''\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size=(128, 128),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size=(128, 128),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 2009s 251ms/step - loss: 0.5206 - acc: 0.7287 - val_loss: 0.5937 - val_acc: 0.7519\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2007s 251ms/step - loss: 0.3700 - acc: 0.8326 - val_loss: 0.6337 - val_acc: 0.7696\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 2001s 250ms/step - loss: 0.2701 - acc: 0.8842 - val_loss: 0.8499 - val_acc: 0.7603\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 1996s 250ms/step - loss: 0.1898 - acc: 0.9229 - val_loss: 1.0563 - val_acc: 0.7636\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2014s 252ms/step - loss: 0.1322 - acc: 0.9489 - val_loss: 1.2506 - val_acc: 0.7493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n* steps_per epoch should equal the number of images in the training set.\\n* can use more than 25 epochs if using a GPU.\\n* validation_steps should equal the number of images in the testing set.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000,\n",
    "                         epochs=5,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000)\n",
    "\n",
    "'''\n",
    "* steps_per epoch should equal the number of images in the training set.\n",
    "* can use more than 25 epochs if using a GPU.\n",
    "* validation_steps should equal the number of images in the testing set.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 2000s 250ms/step - loss: 0.4422 - acc: 0.7867 - val_loss: 0.4387 - val_acc: 0.8086\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 1993s 249ms/step - loss: 0.2941 - acc: 0.8732 - val_loss: 0.4426 - val_acc: 0.8277\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 1998s 250ms/step - loss: 0.2327 - acc: 0.9029 - val_loss: 0.4618 - val_acc: 0.8291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39140594a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000,\n",
    "                         epochs=3,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 2681s 335ms/step - loss: 0.4587 - acc: 0.7683 - val_loss: 0.4706 - val_acc: 0.8254\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 2656s 332ms/step - loss: 0.2396 - acc: 0.8996 - val_loss: 0.5065 - val_acc: 0.8196\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 2661s 333ms/step - loss: 0.1675 - acc: 0.9324 - val_loss: 0.5858 - val_acc: 0.8343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4783466358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000,\n",
    "                         epochs=3,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
